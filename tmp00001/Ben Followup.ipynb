{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why did my answer differ from Ben's example ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\"The cat sat on my head\", \"The dog sat on my bed\"]\n",
    "\n",
    "# TF: how often a given word appears within a document\n",
    "\n",
    "# Example: TF(doc1)\n",
    "#{'The': 0.16666666666666666,\n",
    "# 'cat': 0.16666666666666666,\n",
    "# 'bed': 0.0,\n",
    "# 'dog': 0.0,\n",
    "# 'my': 0.16666666666666666,\n",
    "# 'head': 0.16666666666666666,\n",
    "# 'sat': 0.16666666666666666,\n",
    "# 'on': 0.16666666666666666}\n",
    "\n",
    "# IDF: downscales words that appear a lot across documents\n",
    "# idf(t, D) = log (<total number of documents in the corpus D>   /  \n",
    "# <number of documents in D where the term t appears at least once>)\n",
    "#                     100             3           1\n",
    "\n",
    "## I think this is from from wiki: https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n",
    "## idf(t, D) = {\\displaystyle \\mathrm {tf} (t,d)=0.5+0.5\\cdot {\\frac {f_{t,d}}{\\max\\{f_{t',d}:t'\\in d\\}}}}\n",
    "## {idf} (t,D)=\\log {\\frac {N}{|\\{d\\in D:t\\in d\\}|}}} \\mathrm{idf}(t, D) = \\log \\frac{N}{|\\{d \\in D: t \\in d\\}|}\n",
    "    \n",
    "# Example: \n",
    "# {'on': 0.0, 'dog': 0.3010299956639812, 'bed': 0.3010299956639812, 'face': 0.3010299956639812, \n",
    "#  'The': 0.0, 'cat': 0.3010299956639812, 'my': 0.0, 'sat': 0.0}\n",
    "#\n",
    "#\n",
    "# tf-idf = TF * IDF \n",
    "# Example:\n",
    "# {'on': 0.0, 'dog': 0.0, 'bed': 0.0, 'cat': 0.050171665943996864,\n",
    "#   'The': 0.0, 'face': 0.050171665943996864, 'my': 0.0, 'sat': 0.0}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my implemntation from iview\n",
    "\n",
    "from collections import Counter\n",
    "from math import log\n",
    "\n",
    "def compute_idf(corpora):\n",
    "    c = Counter()\n",
    "    num_doc = len(corpora)\n",
    "    \n",
    "    for doc in corpora:\n",
    "        t = set(doc)\n",
    "        c += Counter(t)  # counter overrides +\n",
    "    \n",
    "    for k in c.keys():\n",
    "        c[k] = log ( num_doc / c[k]) \n",
    "        \n",
    "    return c\n",
    "\n",
    "def compute_tf(terms, idf):\n",
    "    c = Counter(terms)    \n",
    "    for k in c.keys():\n",
    "        c[k] *= idf[k] * 1/len(terms) \n",
    "    return c\n",
    "\n",
    "def tokenize(body):\n",
    "    return body.lower().split()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 0.0, 'head': 0.6931471805599453, 'cat': 0.6931471805599453, 'on': 0.0, 'my': 0.0, 'sat': 0.0, 'bed': 0.6931471805599453, 'dog': 0.6931471805599453}\n"
     ]
    }
   ],
   "source": [
    "idf = compute_idf(list(map(tokenize,[doc1, doc2])))\n",
    "\n",
    "# Example: \n",
    "# {'on': 0.0, 'dog': 0.3010299956639812, 'bed': 0.3010299956639812, 'face': 0.3010299956639812, \n",
    "#  'The': 0.0, 'cat': 0.3010299956639812, 'my': 0.0, 'sat': 0.0}\n",
    "# vs\n",
    "#\n",
    "#\n",
    "#\n",
    "print (dict(idf))\n",
    "# {'the': 0.0, 'head': 0.6931471805599453, 'cat': 0.6931471805599453, 'on': \n",
    "# 0.0, 'my': 0.0, 'sat': 0.0, 'bed': 0.6931471805599453, 'dog': 0.6931471805599453}\n",
    "\n",
    "# We get different a different IDF vector\n",
    "# it's off by a constant factor... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where does 0.3010299956639812 even come from ?\n",
    "# it must be a low integer fraction of some sort, maybe with a smoothing term ?\n",
    "\n",
    "from math import log, exp\n",
    "\n",
    "needle = 0.3010299956639812 \n",
    "\n",
    "def close(a, b, eps=10**-8):\n",
    "    return abs(float(a) - float(b)) < eps\n",
    "K = 1000\n",
    "\n",
    "\n",
    "# loop through all low integer fractions...\n",
    "for i in range(1,K):\n",
    "    for j in range(i,K):\n",
    "        if close( log(float(i)/ j), needle):\n",
    "            print (f\"case a: {i}/{j}\")\n",
    "        if close( log(float(i)/ j + 1), needle):\n",
    "            print (f\"case b: {i}/{j}\")\n",
    "        if close( (float(i)/ j), needle):\n",
    "            print (f\"case c: {i}/{j}\")\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30102999566398114"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nothing !\n",
    "# oh, wait, 0.3010299956639812 = log10(2)  !!\n",
    "log(2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 0.43429448190325176, 'head': 0.735324477567233, 'cat': 0.735324477567233, 'on': 0.43429448190325176, 'my': 0.43429448190325176, 'sat': 0.43429448190325176, 'bed': 0.735324477567233, 'dog': 0.735324477567233}\n"
     ]
    }
   ],
   "source": [
    "E = exp(1)\n",
    "factor = log(E, 10)\n",
    "print ({ k: v * factor for k,v in idf.items() })  # next time use numpy this is dumb\n",
    "\n",
    "# {'the': 0.0, 'head': 0.30102999566398114, 'cat': 0.30102999566398114, 'on': 0.0, 'my': 0.0, \n",
    "# 'sat': 0.0, 'bed': 0.30102999566398114, 'dog': 0.30102999566398114}\n",
    "\n",
    "# yay, that explains it. He used log10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# am I consistent with sklearn ?\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "\n",
    "tokenized = [word_tokenize(d.lower()) for d in docs]\n",
    "cv = CountVectorizer()\n",
    "cv.fit(docs)         \n",
    "\n",
    "counts = cv.transform(docs) # xform to sparse matrix\n",
    "counts /= counts.sum(axis=1)\n",
    "vals = TfidfTransformer(norm=None, smooth_idf=False).fit_transform(counts).todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matching sklearn's smoothing formualtion adding on the smooothing parameter\n",
    "\n",
    "def compute_idf_smoothed(corpora):\n",
    "    c = Counter()\n",
    "    num_doc = len(corpora)\n",
    "    \n",
    "    for doc in corpora:\n",
    "        t = set(doc)\n",
    "        c += Counter(t) \n",
    "        \n",
    "    for k in c.keys():\n",
    "        c[k] = log ( num_doc / c[k]) \n",
    "        c[k] += 1        # to match sklearn\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn\n",
      "{'bed': 0.0, 'cat': 0.2821911967599909, 'dog': 0.0, 'head': 0.2821911967599909, 'my': 0.16666666666666666, 'on': 0.16666666666666666, 'sat': 0.16666666666666666, 'the': 0.16666666666666666}\n",
      "{'bed': 0.2821911967599909, 'cat': 0.0, 'dog': 0.2821911967599909, 'head': 0.0, 'my': 0.16666666666666666, 'on': 0.16666666666666666, 'sat': 0.16666666666666666, 'the': 0.16666666666666666}\n",
      "\n",
      "mine\n",
      "Counter({'cat': 0.2821911967599909, 'head': 0.2821911967599909, 'the': 0.16666666666666666, 'sat': 0.16666666666666666, 'on': 0.16666666666666666, 'my': 0.16666666666666666})\n",
      "Counter({'dog': 0.2821911967599909, 'bed': 0.2821911967599909, 'the': 0.16666666666666666, 'sat': 0.16666666666666666, 'on': 0.16666666666666666, 'my': 0.16666666666666666})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (\"sklearn\")\n",
    "print (dict(zip(cv.get_feature_names(), vals[0].tolist()[0])))\n",
    "print (dict(zip(cv.get_feature_names(), vals[1].tolist()[0])))\n",
    "print()\n",
    "\n",
    "print (\"mine\")\n",
    "idf = compute_idf_smoothed(list(map(tokenize,[doc1, doc2])))\n",
    "print(compute_tf(tokenize(doc1), idf))\n",
    "print(compute_tf(tokenize(doc2), idf))\n",
    "print ()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
